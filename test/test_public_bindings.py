# -*- coding: utf-8 -*-
# Owner(s): ["module: autograd"]

from torch.testing._internal.common_utils import TestCase, run_tests
import pkgutil
import torch
import sys
from typing import Callable
import inspect

class TestPublicBindings(TestCase):
    def test_no_new_bindings(self):
        """
        This test aims to stop the introduction of new JIT bindings into torch._C
        whose names do not start with _. Such bindings are made available as
        torch.XXX, which may not be desirable.

        If your change causes this test to fail, add your new binding to a relevant
        submodule of torch._C, such as torch._C._jit (or other relevant submodule of
        torch._C). If your binding really needs to be available as torch.XXX, add it
        to torch._C and add it to the allowlist below.

        If you have removed a binding, remove it from the allowlist as well.
        """
        # This allowlist contains every binding in torch._C that is copied into torch at
        # the time of writing. It was generated with
        #
        #   {elem for elem in dir(torch._C) if not elem.startswith("_")}
        #
        torch_C_allowlist_superset = {
            "AggregationType",
            "AliasDb",
            "AnyType",
            "Argument",
            "ArgumentSpec",
            "autocast_decrement_nesting",
            "autocast_increment_nesting",
            "AVG",
            "BenchmarkConfig",
            "BenchmarkExecutionStats",
            "BFloat16StorageBase",
            "Block",
            "BoolStorageBase",
            "BoolType",
            "BufferDict",
            "ByteStorageBase",
            "CallStack",
            "Capsule",
            "CharStorageBase",
            "ClassType",
            "clear_autocast_cache",
            "Code",
            "CompilationUnit",
            "CompleteArgumentSpec",
            "ComplexDoubleStorageBase",
            "ComplexFloatStorageBase",
            "ComplexType",
            "ConcreteModuleType",
            "ConcreteModuleTypeBuilder",
            "CONV_BN_FUSION",
            "cpp",
            "CudaBFloat16StorageBase",
            "CudaBFloat16TensorBase",
            "CudaBFloat16TensorBase",
            "CudaBoolStorageBase",
            "CudaBoolTensorBase",
            "CudaBoolTensorBase",
            "CudaByteStorageBase",
            "CudaByteTensorBase",
            "CudaByteTensorBase",
            "CudaCharStorageBase",
            "CudaCharTensorBase",
            "CudaCharTensorBase",
            "CudaComplexDoubleStorageBase",
            "CudaComplexDoubleTensorBase",
            "CudaComplexDoubleTensorBase",
            "CudaComplexFloatStorageBase",
            "CudaComplexFloatTensorBase",
            "CudaComplexFloatTensorBase",
            "CudaDoubleStorageBase",
            "CudaDoubleTensorBase",
            "CudaDoubleTensorBase",
            "CudaFloatStorageBase",
            "CudaFloatTensorBase",
            "CudaHalfStorageBase",
            "CudaHalfTensorBase",
            "CudaIntStorageBase",
            "CudaIntTensorBase",
            "CudaIntTensorBase",
            "CudaLongStorageBase",
            "CudaLongTensorBase",
            "CudaLongTensorBase",
            "CudaShortStorageBase",
            "CudaShortTensorBase",
            "CudaShortTensorBase",
            "DeepCopyMemoTable",
            "default_generator",
            "DeserializationStorageContext",
            "device",
            "DeviceObjType",
            "DictType",
            "DisableTorchFunction",
            "DoubleStorageBase",
            "dtype",
            "EnumType",
            "ErrorReport",
            "ExecutionPlan",
            "FatalError",
            "FileCheck",
            "finfo",
            "FloatStorageBase",
            "FloatType",
            "fork",
            "FunctionSchema",
            "FUSE_ADD_RELU",
            "Future",
            "FutureType",
            "Generator",
            "get_autocast_cpu_dtype",
            "get_default_dtype",
            "get_num_interop_threads",
            "get_num_threads",
            "Gradient",
            "Graph",
            "GraphExecutorState",
            "HalfStorageBase",
            "has_cuda",
            "has_cudnn",
            "has_lapack",
            "has_mkl",
            "has_mkldnn",
            "has_mlc",
            "has_openmp",
            "has_spectral",
            "HOIST_CONV_PACKED_PARAMS",
            "iinfo",
            "import_ir_module_from_buffer",
            "import_ir_module",
            "InferredType",
            "init_num_threads",
            "INSERT_FOLD_PREPACK_OPS",
            "InterfaceType",
            "IntStorageBase",
            "IntType",
            "IODescriptor",
            "is_anomaly_enabled",
            "is_autocast_cache_enabled",
            "is_autocast_cpu_enabled",
            "is_autocast_enabled",
            "is_grad_enabled",
            "is_inference_mode_enabled",
            "JITException",
            "layout",
            "ListType",
            "LiteScriptModule",
            "LockingLogger",
            "LoggerBase",
            "LongStorageBase",
            "memory_format",
            "merge_type_from_type_comment",
            "MobileOptimizerType",
            "ModuleDict",
            "Node",
            "NoneType",
            "NoopLogger",
            "NumberType",
            "OperatorInfo",
            "OptionalType",
            "ParameterDict",
            "parse_ir",
            "parse_schema",
            "parse_type_comment",
            "PyObjectType",
            "PyTorchFileReader",
            "PyTorchFileWriter",
            "QInt32StorageBase",
            "QInt8StorageBase",
            "qscheme",
            "QUInt4x2StorageBase",
            "QUInt2x4StorageBase",
            "QUInt8StorageBase",
            "read_vitals",
            "REMOVE_DROPOUT",
            "RRefType",
            "ScriptClass",
            "ScriptClassFunction",
            "ScriptDict",
            "ScriptDictIterator",
            "ScriptDictKeyIterator",
            "ScriptList",
            "ScriptListIterator",
            "ScriptFunction",
            "ScriptMethod",
            "ScriptModule",
            "ScriptModuleSerializer",
            "ScriptObject",
            "ScriptObjectProperty",
            "SerializationStorageContext",
            "set_anomaly_enabled",
            "set_autocast_cache_enabled",
            "set_autocast_cpu_dtype",
            "set_autocast_cpu_enabled",
            "set_autocast_enabled",
            "set_flush_denormal",
            "set_num_interop_threads",
            "set_num_threads",
            "set_vital",
            "ShortStorageBase",
            "Size",
            "StaticModule",
            "Stream",
            "StreamObjType",
            "StringType",
            "SUM",
            "TensorType",
            "ThroughputBenchmark",
            "TracingState",
            "TupleType",
            "Type",
            "unify_type_list",
            "UnionType",
            "Use",
            "Value",
            "autocast_decrement_nesting",
            "autocast_increment_nesting",
            "clear_autocast_cache",
            "cpp",
            "default_generator",
            "device",
            "dtype",
            "finfo",
            "fork",
            "get_default_dtype",
            "get_num_interop_threads",
            "get_num_threads",
            "has_cuda",
            "has_cudnn",
            "has_lapack",
            "has_mkl",
            "has_mkldnn",
            "has_mlc",
            "has_openmp",
            "iinfo",
            "import_ir_module",
            "import_ir_module_from_buffer",
            "init_num_threads",
            "is_anomaly_enabled",
            "is_autocast_enabled",
            "is_grad_enabled",
            "layout",
            "memory_format",
            "merge_type_from_type_comment",
            "parse_ir",
            "parse_schema",
            "parse_type_comment",
            "qscheme",
            "set_anomaly_enabled",
            "set_autocast_enabled",
            'set_autocast_gpu_dtype',
            'get_autocast_gpu_dtype',
            "set_flush_denormal",
            "set_num_interop_threads",
            "set_num_threads",
            "unify_type_list",
            "vitals_enabled",

            "wait",
        }
        torch_C_bindings = {elem for elem in dir(torch._C) if not elem.startswith("_")}

        # Check that the torch._C bindings are all in the allowlist. Since
        # bindings can change based on how PyTorch was compiled (e.g. with/without
        # CUDA), the two may not be an exact match but the bindings should be
        # a subset of the allowlist.
        difference = torch_C_bindings.difference(torch_C_allowlist_superset)
        msg = f"torch._C had bindings that are not present in the allowlist:\n{difference}"
        self.assertTrue(torch_C_bindings.issubset(torch_C_allowlist_superset), msg)

    def test_correct_module_names(self):
        '''
        An API is considered public, if  its  `__module__` starts with `torch.`
        and there is no name in `__module__` or the object itself that starts with “_”.
        Each public package should either:
        - (preferred) Define `__all__` and all callables and classes in there must have their
         `__module__` start with the current submodule's path. Things not in `__all__` should
          NOT have their `__module__` start with the current submodule.
        - (for simple python-only modules) Not define `__all__` and all the elements in `dir(submod)` must have their
          `__module__` that start with the current submodule.
        '''
        allow_dict = dict(
            {'torch': ['_LegacyStorage',
                       '_StorageBase',
                       '_TypedStorage',
                       '_UntypedStorage',
                       '_assert',
                       '_import_dotted_name',
                       '_initExtension',
                       '_load_global_deps',
                       '_register_device_module'],
             'torch.ao.quantization.fake_quantize': ['_is_fake_quant_script_module',
                                                     '_is_float_qparams',
                                                     '_is_per_channel',
                                                     '_is_per_tensor',
                                                     '_is_symmetric_quant'],
             'torch.ao.quantization.fuse_modules': ['_fuse_modules',
                                                    '_fuse_modules_helper',
                                                    '_get_module',
                                                    '_set_module'],
             'torch.ao.quantization.fx.backend_config.native': ['_get_default_op_backend_config'],
             'torch.ao.quantization.fx.fuse': ['_find_matches'],
             'torch.ao.quantization.fx.graph_module': ['_save_packed_weight'],
             'torch.ao.quantization.observer': ['_ObserverBase',
                                                '_PartialWrapper',
                                                '_is_activation_post_process',
                                                '_is_observer_script_module',
                                                '_is_per_channel_script_obs_instance',
                                                '_with_args',
                                                '_with_callable_args'],
             'torch.ao.quantization.qconfig': ['_get_default_qconfig_dict_helper'],
             'torch.ao.quantization.quantization_mappings': ['_get_special_act_post_process',
                                                             '_has_special_act_post_process'],
             'torch.ao.quantization.quantize': ['_convert',
                                                '_observer_forward_hook',
                                                '_observer_forward_pre_hook',
                                                '_propagate_qconfig_helper',
                                                '_remove_activation_post_process',
                                                '_remove_qconfig'],
             'torch.ao.quantization.quantize_jit': ['_check_forward_method',
                                                    '_check_is_script_module',
                                                    '_convert_jit',
                                                    '_prepare_jit',
                                                    '_quantize_jit'],
             'torch.ao.quantization.utils': ['_parent_name'],
             'torch.ao.sparsity.sparsifier.weight_norm_sparsifier': ['_flat_idx_to_2d'],
             'torch.autograd': ['_is_checkpoint_valid',
                                '_make_grads',
                                '_register_py_tensor_class_for_device',
                                '_tensor_or_tensors_to_tuple'],
             'torch.autograd.function': ['_ContextMethodMixin',
                                         '_HookMixin',
                                         '_iter_None_tensors',
                                         '_iter_filter',
                                         '_iter_jit_values',
                                         '_iter_tensors',
                                         '_iter_tensors_permissive',
                                         '_jit_unwrap_structured',
                                         '_map_tensor_data',
                                         '_nested_map',
                                         '_unflatten'],
             'torch.autograd.functional': ['_as_tuple',
                                           '_as_tuple_nocheck',
                                           '_autograd_grad',
                                           '_check_requires_grad',
                                           '_construct_standard_basis_for',
                                           '_fill_in_zeros',
                                           '_grad_postprocess',
                                           '_grad_preprocess',
                                           '_jacfwd',
                                           '_tuple_postprocess',
                                           '_validate_v'],
             'torch.autograd.grad_mode': ['_DecoratorContextManager'],
             'torch.autograd.gradcheck': ['_adjusted_atol',
                                          '_allclose_with_type_promotion',
                                          '_allocate_jacobians_with_inputs',
                                          '_allocate_jacobians_with_outputs',
                                          '_as_tuple',
                                          '_check_analytical_jacobian_attributes',
                                          '_check_analytical_numerical_equal',
                                          '_check_inputs',
                                          '_check_jacobians_equal',
                                          '_check_no_differentiable_outputs',
                                          '_check_no_differentiable_outputs_fast',
                                          '_check_outputs',
                                          '_combine_jacobian_cols',
                                          '_compute_analytical_jacobian_rows',
                                          '_compute_numerical_gradient',
                                          '_compute_numerical_jvps_wrt_specific_input',
                                          '_differentiable_outputs',
                                          '_dot_with_type_promotion',
                                          '_fast_gradcheck',
                                          '_get_analytical_jacobian',
                                          '_get_analytical_jacobian_forward_ad',
                                          '_get_analytical_vJu_backward_mode',
                                          '_get_analytical_vjps_wrt_specific_output',
                                          '_get_failed_batched_grad_test_msg',
                                          '_get_inp_tensors',
                                          '_get_input_to_perturb',
                                          '_get_notallclose_msg',
                                          '_get_numerical_jacobian',
                                          '_get_numerical_jvp_fn',
                                          '_get_numerical_jvp_wrt_specific_input',
                                          '_get_numerical_vJu',
                                          '_gradcheck_helper',
                                          '_gradcheck_real_imag',
                                          '_is_float_or_complex_tensor',
                                          '_iter_tensor',
                                          '_iter_tensors',
                                          '_make_vectors',
                                          '_mul_tensor_or_tuple',
                                          '_prepare_input',
                                          '_real_and_imag_input',
                                          '_real_and_imag_output',
                                          '_reshape_tensor_or_tuple',
                                          '_run_slow_mode_and_get_error',
                                          '_slow_gradcheck',
                                          '_stack_and_check_tensors',
                                          '_test_backward_mul_by_grad_output',
                                          '_test_batched_grad',
                                          '_test_batched_grad_forward_ad',
                                          '_test_undefined_backward_mode',
                                          '_test_undefined_forward_mode',
                                          '_to_flat_dense_if_sparse',
                                          '_to_real_dtype',
                                          '_transpose',
                                          '_vec_from_tensor',
                                          '_with_prepare_inputs'],
             'torch.autograd.profiler': ['_filter_name',
                                         '_filter_stack_entry',
                                         '_rewrite_name'],
             'torch.autograd.profiler_legacy': ['_parse_legacy_records'],
             'torch.autograd.profiler_util': ['_attr_formatter',
                                              '_build_table',
                                              '_filter_name',
                                              '_filter_stack_entry',
                                              '_format_memory',
                                              '_format_time',
                                              '_format_time_share',
                                              '_rewrite_name'],
             'torch.backends': ['__allow_nonbracketed_mutation'],
             'torch.cuda': ['_CudaBase',
                            '_LazySeedTracker',
                            '_UntypedStorage',
                            '_check_capability',
                            '_check_cubins',
                            '_dummy_type',
                            '_get_device_index',
                            '_lazy_call',
                            '_lazy_init',
                            '_sleep'],
             'torch.cuda.amp.autocast_mode': ['_cast'],
             'torch.cuda.amp.grad_scaler': ['_MultiDeviceReplicator',
                                            '_refresh_per_optimizer_state'],
             'torch.cuda.memory': ['_free_mutex', '_host_allocator'],
             'torch.cuda.nccl': ['_check_sequence_type'],
             'torch.distributed': ['_all_gather_base',
                                   '_create_process_group_wrapper',
                                   '_create_store_from_options',
                                   '_rank_not_in_group',
                                   '_reduce_scatter_base',
                                   '_remote_device'],
             'torch.distributed.algorithms.ddp_comm_hooks': ['_ddp_comm_hook_wrapper',
                                                             '_powerSGD_comm_hook_wrapper'],
             'torch.distributed.algorithms.ddp_comm_hooks.default_hooks': ['_allreduce_fut'],
             'torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks': ['_OptimizerHookState',
                                                                                     '_hook_then_optimizer'],
             'torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook': ['_orthogonalize',
                                                                           '_orthogonalize_gram_schmidt',
                                                                           '_report_compression_stats',
                                                                           '_should_compress'],
             'torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks': ['_dequantize_per_channel_cuda',
                                                                                '_dequantize_per_tensor_cuda',
                                                                                '_get_allgather_out_list',
                                                                                '_quantize_per_channel_cuda',
                                                                                '_quantize_per_tensor_cuda'],
             'torch.distributed.algorithms.join': ['_JoinConfig'],
             'torch.distributed.distributed_c10d': ['_all_gather_base',
                                                    '_batch_p2p_manager',
                                                    '_check_for_nccl_backend',
                                                    '_check_op',
                                                    '_check_p2p_op_list',
                                                    '_check_single_tensor',
                                                    '_check_tensor_list',
                                                    '_create_process_group_wrapper',
                                                    '_get_default_group',
                                                    '_get_default_store',
                                                    '_get_global_rank',
                                                    '_get_group_rank',
                                                    '_get_group_size',
                                                    '_new_process_group_helper',
                                                    '_object_to_tensor',
                                                    '_rank_not_in_group',
                                                    '_reduce_op',
                                                    '_reduce_scatter_base',
                                                    '_store_based_barrier',
                                                    '_tensor_to_object',
                                                    '_update_default_pg',
                                                    '_validate_output_list_for_rank',
                                                    '_warn_not_in_group'],
             'torch.distributed.elastic.agent.server.api': ['_RoleInstanceInfo',
                                                            '_get_fq_hostname',
                                                            '_get_socket_with_port'],
             'torch.distributed.elastic.events': ['_get_or_create_logger'],
             'torch.distributed.elastic.metrics.api': ['_get_metric_name'],
             'torch.distributed.elastic.multiprocessing': ['_validate_full_rank'],
             'torch.distributed.elastic.multiprocessing.api': ['_get_default_signal',
                                                               '_get_kill_signal',
                                                               '_terminate_process_handler',
                                                               '_validate_full_rank',
                                                               '_wrap'],
             'torch.distributed.elastic.multiprocessing.redirects': ['_c_std',
                                                                     '_python_std'],
             'torch.distributed.elastic.rendezvous': ['_register_default_handlers'],
             'torch.distributed.elastic.rendezvous.dynamic_rendezvous': ['_Action',
                                                                         '_BackendRendezvousStateHolder',
                                                                         '_DistributedRendezvousOpExecutor',
                                                                         '_NodeDesc',
                                                                         '_NodeDescGenerator',
                                                                         '_RendezvousCloseOp',
                                                                         '_RendezvousContext',
                                                                         '_RendezvousExitOp',
                                                                         '_RendezvousJoinOp',
                                                                         '_RendezvousKeepAliveOp',
                                                                         '_RendezvousOpExecutor',
                                                                         '_RendezvousState',
                                                                         '_RendezvousStateHolder',
                                                                         '_get_timeout',
                                                                         '_remove_participant_epilogue',
                                                                         '_should_keep_alive'],
             'torch.distributed.elastic.rendezvous.registry': ['_create_c10d_handler',
                                                               '_create_etcd_handler',
                                                               '_create_etcd_v2_handler',
                                                               '_create_static_handler',
                                                               '_register_default_handlers'],
             'torch.distributed.elastic.rendezvous.utils': ['_PeriodicTimer',
                                                            '_delay',
                                                            '_matches_machine_hostname',
                                                            '_parse_rendezvous_config',
                                                            '_try_parse_port'],
             'torch.distributed.elastic.utils.logging': ['_derive_module_name',
                                                         '_setup_logger'],
             'torch.distributed.fsdp.flatten_params_wrapper': ['_post_state_dict_hook',
                                                               '_pre_load_state_dict_hook'],
             'torch.distributed.fsdp.fully_sharded_data_parallel': ['_alloc_storage',
                                                                    '_calc_grad_norm',
                                                                    '_free_storage',
                                                                    '_get_default_cuda_device'],
             'torch.distributed.fsdp.utils': ['_apply_to_tensors',
                                              '_replace_by_prefix'],
             'torch.distributed.fsdp.wrap': ['_ConfigAutoWrap',
                                             '_recursive_wrap',
                                             '_wrap'],
             'torch.distributed.launcher.api': ['_get_addr_and_port',
                                                '_get_entrypoint_name'],
             'torch.distributed.nn.api.remote_module': ['_RemoteModule',
                                                        '_SerializedRemoteModule',
                                                        '_create_module',
                                                        '_create_module_with_interface',
                                                        '_instantiate_template',
                                                        '_param_rrefs',
                                                        '_raise_not_supported',
                                                        '_recursive_script_module_receiver',
                                                        '_recursive_script_module_reducer',
                                                        '_remote_module_receiver',
                                                        '_remote_module_reducer'],
             'torch.distributed.nn.functional': ['_AllGather',
                                                 '_AllReduce',
                                                 '_AlltoAll',
                                                 '_AlltoAllSingle',
                                                 '_Broadcast',
                                                 '_Gather',
                                                 '_Reduce',
                                                 '_Reduce_Scatter',
                                                 '_Scatter'],
             'torch.distributed.nn.jit.instantiator': ['_do_instantiate_remote_module_template',
                                                       '_write'],
             'torch.distributed.optim': ['_FunctionalAdadelta',
                                         '_FunctionalAdagrad',
                                         '_FunctionalAdam',
                                         '_FunctionalAdamW',
                                         '_FunctionalAdamax',
                                         '_FunctionalRMSprop',
                                         '_FunctionalRprop',
                                         '_FunctionalSGD'],
             'torch.distributed.optim.functional_adadelta': ['_FunctionalAdadelta'],
             'torch.distributed.optim.functional_adagrad': ['_FunctionalAdagrad'],
             'torch.distributed.optim.functional_adam': ['_FunctionalAdam'],
             'torch.distributed.optim.functional_adamax': ['_FunctionalAdamax'],
             'torch.distributed.optim.functional_adamw': ['_FunctionalAdamW'],
             'torch.distributed.optim.functional_rmsprop': ['_FunctionalRMSprop'],
             'torch.distributed.optim.functional_rprop': ['_FunctionalRprop'],
             'torch.distributed.optim.functional_sgd': ['_FunctionalSGD'],
             'torch.distributed.optim.optimizer': ['_LocalOptimizer',
                                                   '_ScriptLocalOptimizer',
                                                   '_ScriptLocalOptimizerInterface',
                                                   '_local_optimizer_step',
                                                   '_new_local_optimizer',
                                                   '_new_script_local_optimizer',
                                                   '_wait_for_all'],
             'torch.distributed.optim.utils': ['_create_functional_optim'],
             'torch.distributed.optim.zero_redundancy_optimizer': ['_DDPBucketAssignment',
                                                                   '_OverlapInfo',
                                                                   '_OverlapStatus',
                                                                   '_ZeROJoinHook',
                                                                   '_broadcast_object',
                                                                   '_get_global_rank',
                                                                   '_is_trainable',
                                                                   '_recursive_copy_to_device'],
             'torch.distributed.pipeline.sync.pipe': ['_assemble_partition',
                                                      '_recommend_auto_balance',
                                                      '_retrieve_device',
                                                      '_split_module',
                                                      '_verify_module',
                                                      '_verify_splitting'],
             'torch.distributed.pipeline.sync.pipeline': ['_clock_cycles',
                                                          '_copy',
                                                          '_depend',
                                                          '_wait'],
             'torch.distributed.remote_device': ['_remote_device'],
             'torch.distributed.rendezvous': ['_create_c10d_store',
                                              '_create_store_from_options',
                                              '_env_rendezvous_handler',
                                              '_file_rendezvous_handler',
                                              '_query_to_dict',
                                              '_rendezvous_error',
                                              '_tcp_rendezvous_handler',
                                              '_torchelastic_use_agent_store'],
             'torch.distributed.rpc': ['_get_debug_info',
                                       '_init_rpc_backend',
                                       '_server_process_global_profile',
                                       '_validate_rpc_args'],
             'torch.distributed.rpc.api': ['_all_gather',
                                           '_barrier',
                                           '_broadcast_to_followers',
                                           '_enable_rpc_profiler',
                                           '_finalize_shutdown',
                                           '_gather_to_leader',
                                           '_init_rpc_states',
                                           '_invoke_rpc',
                                           '_require_initialized',
                                           '_rref_typeof_on_owner',
                                           '_rref_typeof_on_user',
                                           '_to_worker_info',
                                           '_use_rpc_pickler',
                                           '_wait_all',
                                           '_wait_all_workers'],
             'torch.distributed.rpc.backend_registry': ['_backend_type_repr',
                                                        '_init_process_group',
                                                        '_tensorpipe_check_local_device_maps',
                                                        '_tensorpipe_construct_rpc_backend_options_handler',
                                                        '_tensorpipe_exchange_and_check_all_device_maps',
                                                        '_tensorpipe_init_backend_handler',
                                                        '_tensorpipe_validate_devices'],
             'torch.distributed.rpc.internal': ['_InternalRPCPickler',
                                                '_build_rpc_profiling_key',
                                                '_handle_exception',
                                                '_run_function',
                                                '_start_record_function'],
             'torch.distributed.rpc.options': ['_to_device',
                                               '_to_device_list',
                                               '_to_device_map'],
             'torch.distributed.rpc.server_process_global_profiler': ['_server_process_global_profile'],
             'torch.distributions.binomial': ['_clamp_by_zero'],
             'torch.distributions.constraint_registry': ['_biject_to_cat',
                                                         '_biject_to_independent',
                                                         '_biject_to_simplex',
                                                         '_biject_to_stack',
                                                         '_transform_to_cat',
                                                         '_transform_to_corr_cholesky',
                                                         '_transform_to_greater_than',
                                                         '_transform_to_independent',
                                                         '_transform_to_interval',
                                                         '_transform_to_less_than',
                                                         '_transform_to_lower_cholesky',
                                                         '_transform_to_positive',
                                                         '_transform_to_real',
                                                         '_transform_to_simplex',
                                                         '_transform_to_stack'],
             'torch.distributions.constraints': ['_Boolean',
                                                 '_Cat',
                                                 '_CorrCholesky',
                                                 '_Dependent',
                                                 '_DependentProperty',
                                                 '_GreaterThan',
                                                 '_GreaterThanEq',
                                                 '_HalfOpenInterval',
                                                 '_IndependentConstraint',
                                                 '_IntegerGreaterThan',
                                                 '_IntegerInterval',
                                                 '_IntegerLessThan',
                                                 '_Interval',
                                                 '_LessThan',
                                                 '_LowerCholesky',
                                                 '_LowerTriangular',
                                                 '_Multinomial',
                                                 '_OneHot',
                                                 '_PositiveDefinite',
                                                 '_PositiveSemidefinite',
                                                 '_Real',
                                                 '_Simplex',
                                                 '_Square',
                                                 '_Stack',
                                                 '_Symmetric'],
             'torch.distributions.dirichlet': ['_Dirichlet',
                                               '_Dirichlet_backward'],
             'torch.distributions.gamma': ['_standard_gamma'],
             'torch.distributions.kl': ['_Match',
                                        '_add_kl_info',
                                        '_batch_trace_XXT',
                                        '_dispatch_kl',
                                        '_infinite_like',
                                        '_kl_bernoulli_bernoulli',
                                        '_kl_bernoulli_poisson',
                                        '_kl_beta_beta',
                                        '_kl_beta_continuous_bernoulli',
                                        '_kl_beta_exponential',
                                        '_kl_beta_gamma',
                                        '_kl_beta_infinity',
                                        '_kl_beta_normal',
                                        '_kl_beta_uniform',
                                        '_kl_binomial_binomial',
                                        '_kl_categorical_categorical',
                                        '_kl_cauchy_cauchy',
                                        '_kl_continuous_bernoulli_continuous_bernoulli',
                                        '_kl_continuous_bernoulli_exponential',
                                        '_kl_continuous_bernoulli_infinity',
                                        '_kl_continuous_bernoulli_normal',
                                        '_kl_continuous_bernoulli_uniform',
                                        '_kl_dirichlet_dirichlet',
                                        '_kl_expfamily_expfamily',
                                        '_kl_exponential_exponential',
                                        '_kl_exponential_gamma',
                                        '_kl_exponential_gumbel',
                                        '_kl_exponential_infinity',
                                        '_kl_exponential_normal',
                                        '_kl_gamma_exponential',
                                        '_kl_gamma_gamma',
                                        '_kl_gamma_gumbel',
                                        '_kl_gamma_infinity',
                                        '_kl_gamma_normal',
                                        '_kl_geometric_geometric',
                                        '_kl_gumbel_gumbel',
                                        '_kl_gumbel_infinity',
                                        '_kl_gumbel_normal',
                                        '_kl_halfnormal_halfnormal',
                                        '_kl_independent_independent',
                                        '_kl_laplace_infinity',
                                        '_kl_laplace_laplace',
                                        '_kl_laplace_normal',
                                        '_kl_lowrankmultivariatenormal_lowrankmultivariatenormal',
                                        '_kl_lowrankmultivariatenormal_multivariatenormal',
                                        '_kl_multivariatenormal_lowrankmultivariatenormal',
                                        '_kl_multivariatenormal_multivariatenormal',
                                        '_kl_normal_gumbel',
                                        '_kl_normal_infinity',
                                        '_kl_normal_laplace',
                                        '_kl_normal_normal',
                                        '_kl_onehotcategorical_onehotcategorical',
                                        '_kl_pareto_exponential',
                                        '_kl_pareto_gamma',
                                        '_kl_pareto_infinity',
                                        '_kl_pareto_normal',
                                        '_kl_pareto_pareto',
                                        '_kl_poisson_infinity',
                                        '_kl_poisson_poisson',
                                        '_kl_transformed_transformed',
                                        '_kl_uniform_beta',
                                        '_kl_uniform_continuous_bernoulli',
                                        '_kl_uniform_exponetial',
                                        '_kl_uniform_gamma',
                                        '_kl_uniform_gumbel',
                                        '_kl_uniform_normal',
                                        '_kl_uniform_pareto',
                                        '_kl_uniform_uniform',
                                        '_x_log_x'],
             'torch.distributions.kumaraswamy': ['_moments'],
             'torch.distributions.lowrank_multivariate_normal': ['_batch_capacitance_tril',
                                                                 '_batch_lowrank_logdet',
                                                                 '_batch_lowrank_mahalanobis'],
             'torch.distributions.multivariate_normal': ['_batch_mahalanobis',
                                                         '_batch_mv',
                                                         '_precision_to_scale_tril'],
             'torch.distributions.transforms': ['_InverseTransform',
                                                '_clipped_sigmoid'],
             'torch.distributions.utils': ['_lazy_property_and_property',
                                           '_standard_normal',
                                           '_sum_rightmost'],
             'torch.distributions.von_mises': ['_eval_poly',
                                               '_log_modified_bessel_fn',
                                               '_rejection_sample'],
             'torch.distributions.wishart': ['_clamp_above_eps', '_mvdigamma'],
             'torch.functional': ['_check_list_size',
                                  '_consecutive_return_counts',
                                  '_consecutive_return_inverse',
                                  '_consecutive_return_inverse_false',
                                  '_consecutive_return_inverse_true',
                                  '_consecutive_return_output',
                                  '_lu_impl',
                                  '_lu_no_infos',
                                  '_lu_with_infos',
                                  '_meshgrid',
                                  '_return_counts',
                                  '_return_inverse',
                                  '_return_inverse_false',
                                  '_return_inverse_true',
                                  '_return_output',
                                  '_unique_consecutive_impl',
                                  '_unique_impl'],
             'torch.futures': ['_PyFutureMeta'],
             'torch.fx.experimental.unification.more': ['_reify_object_dict',
                                                        '_reify_object_slots'],
             'torch.fx.experimental.unification.multipledispatch.utils': ['_toposort'],
             'torch.fx.experimental.unification.unification_tools': ['_get_factory'],
             'torch.fx.experimental.unification.utils': ['_toposort'],
             'torch.fx.graph': ['_CustomBuiltin',
                                '_InsertPoint',
                                '_Namespace',
                                '_PyTreeCodeGen',
                                '_PyTreeInfo',
                                '_format_target',
                                '_is_from_torch',
                                '_is_magic',
                                '_node_list',
                                '_register_custom_builtin',
                                '_snake_case'],
             'torch.fx.graph_module': ['_EvalCacheLoader',
                                       '_assign_attr',
                                       '_copy_attr',
                                       '_deserialize_graph_module',
                                       '_exec_with_source',
                                       '_format_import_block',
                                       '_format_import_statement',
                                       '_forward_from_src'],
             'torch.fx.immutable_collections': ['_create_immutable_container',
                                                '_immutable_dict_flatten',
                                                '_immutable_dict_unflatten',
                                                '_immutable_list_flatten',
                                                '_immutable_list_unflatten',
                                                '_no_mutation'],
             'torch.fx.node': ['_find_module_of_method',
                               '_format_arg',
                               '_get_qualified_name',
                               '_type_repr'],
             'torch.fx.operator_schemas': ['_FakeGlobalNamespace',
                                           '_args_kwargs_to_normalized_args_kwargs',
                                           '_nonzero_schemas',
                                           '_torchscript_schema_to_signature',
                                           '_torchscript_type_to_python_type'],
             'torch.fx.passes.net_min_base': ['_MinimizerBase',
                                              '_MinimizerSettingBase'],
             'torch.fx.passes.operator_support': ['_get_arg_dtype'],
             'torch.fx.passes.shape_prop': ['_extract_tensor_metadata'],
             'torch.fx.passes.splitter_base': ['_SplitterBase',
                                               '_SplitterSettingBase'],
             'torch.fx.proxy': ['_define_reflectable', '_scope'],
             'torch.fx.subgraph_rewriter': ['_SubgraphMatcher',
                                            '_replace_submodules'],
             'torch.hub': ['_check_dependencies',
                           '_check_module_exists',
                           '_get_cache_or_reload',
                           '_get_torch_home',
                           '_git_archive_link',
                           '_import_module',
                           '_is_legacy_zip_format',
                           '_legacy_zip_load',
                           '_load_attr_from_module',
                           '_load_entry_from_hubconf',
                           '_load_local',
                           '_parse_repo_info',
                           '_read_url',
                           '_remove_if_exists',
                           '_validate_not_a_forked_repo'],
             'torch.jit': ['_InsertPoint',
                           '_ScriptProfile',
                           '_fork',
                           '_get_trace_graph',
                           '_hide_source_ranges',
                           '_script_if_tracing',
                           '_set_fusion_strategy',
                           '_unique_state_dict',
                           '_unwrap_optional',
                           '_wait'],
             'torch.multiprocessing': ['_prctl_pr_set_pdeathsig'],
             'torch.multiprocessing.spawn': ['_wrap'],
             'torch.nn.functional': ['_adaptive_max_pool1d',
                                     '_adaptive_max_pool2d',
                                     '_adaptive_max_pool3d',
                                     '_fractional_max_pool2d',
                                     '_fractional_max_pool3d',
                                     '_get_softmax_dim',
                                     '_in_projection',
                                     '_in_projection_packed',
                                     '_max_pool1d',
                                     '_max_pool2d',
                                     '_max_pool3d',
                                     '_mha_shape_check',
                                     '_no_grad_embedding_renorm_',
                                     '_pad',
                                     '_pad_circular',
                                     '_scaled_dot_product_attention',
                                     '_threshold',
                                     '_unpool_output_size',
                                     '_verify_batch_size',
                                     '_verify_spatial_size'],
             'torch.nn.grad': ['_grad_input_padding'],
             'torch.nn.init': ['_calculate_correct_fan',
                               '_calculate_fan_in_and_fan_out',
                               '_make_deprecate',
                               '_no_grad_fill_',
                               '_no_grad_normal_',
                               '_no_grad_trunc_normal_',
                               '_no_grad_uniform_',
                               '_no_grad_zero_'],
             'torch.nn.intrinsic': ['_FusedModule'],
             'torch.nn.intrinsic.modules': ['_FusedModule'],
             'torch.nn.intrinsic.modules.fused': ['_FusedModule'],
             'torch.nn.intrinsic.qat.modules.conv_fused': ['_ConvBnNd'],
             'torch.nn.modules.adaptive': ['_ASMoutput'],
             'torch.nn.modules.batchnorm': ['_BatchNorm',
                                            '_LazyNormBase',
                                            '_NormBase'],
             'torch.nn.modules.conv': ['_ConvNd',
                                       '_ConvTransposeMixin',
                                       '_ConvTransposeNd',
                                       '_LazyConvXdMixin'],
             'torch.nn.modules.dropout': ['_DropoutNd'],
             'torch.nn.modules.instancenorm': ['_InstanceNorm'],
             'torch.nn.modules.lazy': ['_LazyProtocol'],
             'torch.nn.modules.loss': ['_Loss', '_WeightedLoss'],
             'torch.nn.modules.module': ['_IncompatibleKeys',
                                         '_addindent',
                                         '_forward_unimplemented'],
             'torch.nn.modules.padding': ['_ConstantPadNd',
                                          '_ReflectionPadNd',
                                          '_ReplicationPadNd'],
             'torch.nn.modules.pooling': ['_AdaptiveAvgPoolNd',
                                          '_AdaptiveMaxPoolNd',
                                          '_AvgPoolNd',
                                          '_LPPoolNd',
                                          '_MaxPoolNd',
                                          '_MaxUnpoolNd'],
             'torch.nn.modules.transformer': ['_get_activation_fn',
                                              '_get_clones'],
             'torch.nn.modules.utils': ['_list_with_default',
                                        '_ntuple',
                                        '_pair',
                                        '_quadruple',
                                        '_reverse_repeat_tuple',
                                        '_single',
                                        '_triple'],
             'torch.nn.parallel.data_parallel': ['_check_balance'],
             'torch.nn.parallel.distributed': ['_BufferCommHook',
                                               '_BufferCommHookLocation',
                                               '_DDPJoinHook',
                                               '_DDPSink',
                                               '_dump_DDP_relevant_env_vars',
                                               '_find_tensors',
                                               '_tree_flatten_with_rref',
                                               '_tree_unflatten_with_rref'],
             'torch.nn.parallel.replicate': ['_broadcast_coalesced_reshape',
                                             '_init_script_module',
                                             '_is_jit_enabled',
                                             '_is_script_method',
                                             '_is_script_module',
                                             '_replicatable_module'],
             'torch.nn.qat.modules.conv': ['_ConvNd'],
             'torch.nn.quantizable.modules.rnn': ['_LSTMLayer',
                                                  '_LSTMSingleLayer'],
             'torch.nn.quantized': ['_ConvNd'],
             'torch.nn.quantized.modules': ['_ConvNd'],
             'torch.nn.quantized.modules.batchnorm': ['_BatchNorm'],
             'torch.nn.quantized.modules.conv': ['_ConvNd',
                                                 '_ConvTransposeNd',
                                                 '_reverse_repeat_padding'],
             'torch.nn.quantized.modules.utils': ['_ntuple_from_first',
                                                  '_pair_from_first',
                                                  '_quantize_weight'],
             'torch.nn.utils.convert_parameters': ['_check_param_device'],
             'torch.nn.utils.parametrizations': ['_OrthMaps',
                                                 '_Orthogonal',
                                                 '_SpectralNorm',
                                                 '_is_orthogonal',
                                                 '_make_orthogonal'],
             'torch.nn.utils.parametrize': ['_inject_new_class',
                                            '_inject_property',
                                            '_register_parameter_or_buffer'],
             'torch.nn.utils.rnn': ['_packed_sequence_init',
                                    '_packed_sequence_init_args'],
             'torch.onnx': ['_export',
                            '_optimize_trace',
                            '_run_symbolic_function',
                            '_run_symbolic_method'],
             'torch.optim.adadelta': ['_multi_tensor_adadelta',
                                      '_single_tensor_adadelta'],
             'torch.optim.adagrad': ['_make_sparse',
                                     '_multi_tensor_adagrad',
                                     '_single_tensor_adagrad'],
             'torch.optim.adam': ['_multi_tensor_adam', '_single_tensor_adam'],
             'torch.optim.adamax': ['_multi_tensor_adamax',
                                    '_single_tensor_adamax'],
             'torch.optim.adamw': ['_multi_tensor_adamw',
                                   '_single_tensor_adamw'],
             'torch.optim.asgd': ['_multi_tensor_asgd', '_single_tensor_asgd'],
             'torch.optim.lbfgs': ['_cubic_interpolate', '_strong_wolfe'],
             'torch.optim.lr_scheduler': ['_LRScheduler'],
             'torch.optim.nadam': ['_multi_tensor_nadam',
                                   '_single_tensor_nadam'],
             'torch.optim.optimizer': ['_RequiredParameter'],
             'torch.optim.radam': ['_multi_tensor_radam',
                                   '_single_tensor_radam'],
             'torch.optim.rmsprop': ['_multi_tensor_rmsprop',
                                     '_single_tensor_rmsprop'],
             'torch.optim.rprop': ['_multi_tensor_rprop',
                                   '_single_tensor_rprop'],
             'torch.optim.sgd': ['_multi_tensor_sgd', '_single_tensor_sgd'],
             'torch.overrides': ['_get_overloaded_args', '_get_tensor_methods'],
             'torch.package.file_structure_representation': ['_create_directory_from_file_list'],
             'torch.package.find_file_dependencies': ['_ExtractModuleReferences'],
             'torch.package.importer': ['_SysImporter'],
             'torch.package.package_exporter': ['_ModuleProviderAction',
                                                '_PatternInfo',
                                                '_read_file'],
             'torch.package.package_importer': ['_ExternNode',
                                                '_ModuleNode',
                                                '_PackageNode',
                                                '_PackageResourceReader',
                                                '_PathNode'],
             'torch.profiler': ['_KinetoProfile'],
             'torch.profiler.profiler': ['_KinetoProfile',
                                         '_default_schedule_fn'],
             'torch.return_types': ['_det_lu_based_helper',
                                    '_fake_quantize_per_tensor_affine_cachemask_tensor_qparams',
                                    '_fused_moving_avg_obs_fq_helper',
                                    '_linalg_svd',
                                    '_linalg_svd_out',
                                    '_lu_with_info',
                                    '_unpack_dual'],
             'torch.serialization': ['_check_dill_version',
                                     '_check_seekable',
                                     '_cpu_deserialize',
                                     '_cpu_tag',
                                     '_cuda_deserialize',
                                     '_cuda_tag',
                                     '_get_layout',
                                     '_get_restore_location',
                                     '_is_compressed_file',
                                     '_is_path',
                                     '_is_torchscript_zip',
                                     '_is_zipfile',
                                     '_legacy_load',
                                     '_legacy_save',
                                     '_load',
                                     '_maybe_decode_ascii',
                                     '_open_buffer_reader',
                                     '_open_buffer_writer',
                                     '_open_file',
                                     '_open_file_like',
                                     '_open_zipfile_reader',
                                     '_open_zipfile_writer',
                                     '_open_zipfile_writer_buffer',
                                     '_open_zipfile_writer_file',
                                     '_opener',
                                     '_save',
                                     '_should_read_directly'],
             'torch.storage': ['_LegacyStorage',
                               '_LegacyStorageMeta',
                               '_StorageBase',
                               '_TypedStorage',
                               '_dtype_to_storage_type_map',
                               '_get_dtype_from_pickle_storage_type',
                               '_get_storage_from_sequence',
                               '_isint',
                               '_load_from_bytes',
                               '_storage_type_to_dtype_map'],
             'torch.testing': ['_dispatch_dtypes', '_validate_dtypes'],
             'torch.torch_version': ['_LazyImport'],
             'torch.utils.benchmark.utils.common': ['_make_temp_dir'],
             'torch.utils.benchmark.utils.compare': ['_Column', '_Row'],
             'torch.utils.benchmark.utils.cpp_jit': ['_compile_template',
                                                     '_get_build_root'],
             'torch.utils.benchmark.utils.valgrind_wrapper.timer_interface': ['_ValgrindWrapper'],
             'torch.utils.cpp_extension': ['_accepted_compilers_for_platform',
                                           '_find_cuda_home',
                                           '_find_rocm_home',
                                           '_get_build_directory',
                                           '_get_cuda_arch_flags',
                                           '_get_exec_path',
                                           '_get_num_workers',
                                           '_get_rocm_arch_flags',
                                           '_import_module_from_library',
                                           '_is_binary_build',
                                           '_is_cuda_file',
                                           '_jit_compile',
                                           '_join_cuda_home',
                                           '_join_rocm_home',
                                           '_nt_quote_args',
                                           '_prepare_ldflags',
                                           '_run_ninja_build',
                                           '_write_ninja_file',
                                           '_write_ninja_file_and_build_library',
                                           '_write_ninja_file_and_compile_objects',
                                           '_write_ninja_file_to_build_library'],
             'torch.utils.data': ['_DatasetKind'],
             'torch.utils.data.dataloader': ['_BaseDataLoaderIter',
                                             '_DatasetKind',
                                             '_InfiniteConstantSampler',
                                             '_MultiProcessingDataLoaderIter',
                                             '_SingleProcessDataLoaderIter'],
             'torch.utils.data.dataloader_experimental': ['_ThreadingDataLoader2',
                                                          '_sharding_worker_init_fn'],
             'torch.utils.data.datapipes.dataframe.dataframe_wrapper': ['_try_import_pandas',
                                                                        '_with_pandas'],
             'torch.utils.data.datapipes.iter.combining': ['_ChildDataPipe',
                                                           '_DemultiplexerIterDataPipe',
                                                           '_ForkerIterDataPipe'],
             'torch.utils.tensorboard.summary': ['_calc_scale_factor',
                                                 '_draw_single_box',
                                                 '_get_json_config',
                                                 '_get_tensor_summary']})
        failure_list = []

        def add_to_failure_list_if_not_in_allow_dict(modname, elem, elem_module):
            if modname in allow_dict and elem in allow_dict[modname]:
                return
            failure_list.append((modname, elem, elem_module))

        def test_module(modname):
            split_strs = modname.split('.')
            mod = sys.modules.get(modname)
            for elem in split_strs:
                if elem.startswith("_"):
                    return

            # verifies that each API has the correct module name and naming semantics
            # depending on whether it's public or private
            def looks_public(elem, modname, mod, private_api):
                obj = getattr(mod, elem)
                if not (isinstance(obj, Callable) or inspect.isclass(obj)):
                    return
                elem_module = getattr(obj, '__module__', None)
                elem_modname_starts_with_modname = elem_module is not None and elem_module.startswith(modname)
                if private_api:
                    # elem's name must begin with an `_` and it's module name
                    # should NOT start with it's current module since it's a private API
                    if elem_modname_starts_with_modname:
                        add_to_failure_list_if_not_in_allow_dict(modname, elem, elem_module)
                else:
                    # elem's name must NOT begin with an `_` and it's module name
                    # SHOULD start with it's current module since it's a public API
                    if elem.startswith('_') and not elem_modname_starts_with_modname:
                        add_to_failure_list_if_not_in_allow_dict(modname, elem, elem_module)

            if hasattr(modname, '__all__'):
                public_api = mod.__all__
                all_api = dir(modname)
                for elem in all_api:
                    looks_public(elem, modname, elem not in public_api)
            else:
                all_api = dir(mod)
                for elem in all_api:
                    looks_public(elem, modname, mod, elem.startswith('_'))

        for _, modname, ispkg in pkgutil.walk_packages(path=torch.__path__, prefix=torch.__name__ + '.'):
            test_module(modname)

        test_module('torch')
        msg = "Following new APIs ( displayed in the form (module, element, element module) )" \
              " were added that do not meet our guidelines for public API" \
              " and don't have an entry in the allow_dict :\n" + "\n".join(map(str, failure_list))
        # empty lists are considered false in python
        self.assertTrue(not failure_list, msg)

if __name__ == '__main__':
    run_tests()
